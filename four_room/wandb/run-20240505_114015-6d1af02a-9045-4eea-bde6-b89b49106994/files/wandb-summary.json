{"epoch": 3, "alpha_loss": -1.7695919275283813, "critic_loss": 0.06979374587535858, "actor_loss": -6.053098678588867, "batch_entropy": -0.8822959661483765, "alpha": 0.39046597480773926, "q_policy_std": 0.12681305408477783, "q_random_std": 0.1255180537700653, "_timestamp": 1714902221.29154, "_runtime": 205.52091789245605, "_step": 33, "eval/reward_mean": 0.0, "eval/reward_std": 0.0}